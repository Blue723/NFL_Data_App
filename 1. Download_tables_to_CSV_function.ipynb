{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42a90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad3256-f290-431e-b975-730ce8bf5404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224da9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is grabing the 49ers html web page\n",
    "url = 'https://www.pro-football-reference.com/teams/sfo/2010.htm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360332a3",
   "metadata": {},
   "source": [
    "# Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fdaca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function before creating tables\n",
    "def tables_html(url:str):\n",
    "    html = requests.get(url).text\n",
    "    \n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    tables = soup.find_all(class_='table_wrapper')\n",
    "    \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc55cda5-1708-4d07-9d6c-192a5006631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = tables_html(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec84d2e",
   "metadata": {},
   "source": [
    "# DF Columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873c01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_columns (tables:str, table_num:int):\n",
    "\n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "    \n",
    "    \n",
    "    #find thead tag to isolate col names\n",
    "    table_html = table_html.find_all('thead')[0]\n",
    "\n",
    "    # find class_ = 'poptip' to isolate col names\n",
    "    col_th_tag = table_html.find_all(class_='poptip')\n",
    "\n",
    "    # get how many column names there are\n",
    "    num_col_passing = len(col_th_tag)\n",
    "\n",
    "    # list of column names\n",
    "    columns = []\n",
    "\n",
    "    for i in range(0, num_col_passing):\n",
    "        try:\n",
    "            data = col_th_tag[i].contents[0]\n",
    "            columns.append(data)\n",
    "        except:\n",
    "            columns.append('n/a')   \n",
    "            \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e2645",
   "metadata": {},
   "source": [
    "# DF Rows!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7b3cd",
   "metadata": {},
   "source": [
    "## Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61c8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_index(tables:str, table_num:int):\n",
    "    \n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "\n",
    "    rows_tbody = table_html.find_all('tbody')[0]\n",
    "    \n",
    "       \n",
    "    #get index\n",
    "    num_index = len(rows_tbody.find_all('th'))\n",
    "    \n",
    "    index = []\n",
    "    for i in range(0, num_index):\n",
    "    \n",
    "        try:\n",
    "            data = rows_tbody.find_all('th')[i].contents[0]\n",
    "            index.append(data)\n",
    "        except:\n",
    "            index.append('n/a')\n",
    "        \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e3a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_rows(tables:str, table_num:int):\n",
    "    \n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "\n",
    "    rows_tbody = table_html.find_all('tbody')[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    rows_tr = rows_tbody.find_all('tr')\n",
    "    \n",
    "    num_index = len(rows_tbody.find_all('th'))\n",
    "    num_rows = len(rows_tr[0].find_all('td'))\n",
    "    \n",
    "    \n",
    "    row_data = []\n",
    "\n",
    "    for i in range(0, num_index):\n",
    "        row_td = rows_tr[i].find_all('td')\n",
    "    \n",
    "        data = []\n",
    "\n",
    "        for c in range(0, num_rows):\n",
    "            \n",
    "            try:\n",
    "                if len(row_td[c].find_all('a')) > 0:\n",
    "            \n",
    "                    d = row_td[c].find_all('a')[0].contents[0]\n",
    "                    data.append(d)\n",
    "                \n",
    "                else:\n",
    "                    d = row_td[c].contents[0]\n",
    "                    data.append(d)\n",
    "            \n",
    "            except:\n",
    "                data.append('n/a')\n",
    "        \n",
    "\n",
    "        row_data.append(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    index = []\n",
    "    for i in range(0, num_index):\n",
    "    \n",
    "        try:\n",
    "            data = rows_tbody.find_all('th')[i].contents[0]\n",
    "            index.append(data)\n",
    "        except:\n",
    "            index.append('n/a')\n",
    "        \n",
    "        \n",
    "    #insert index to each row to be equal to all columns\n",
    "    for i in range(0, len(index)):\n",
    "        row_data[i].insert(0, index[i])\n",
    "        \n",
    "        \n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb4aa0",
   "metadata": {},
   "source": [
    "# DF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ba8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_tables(tables:str, table_num:int):\n",
    "    \n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "\n",
    "    rows_tbody = table_html.find_all('tbody')[0]\n",
    "    \n",
    "    \n",
    "    #columns\n",
    "    #find thead tag to isolate col names\n",
    "    table_html = table_html.find_all('thead')[0]\n",
    "\n",
    "    # find class_ = 'poptip' to isolate col names\n",
    "    col_th_tag = table_html.find_all(class_='poptip')\n",
    "\n",
    "    # get how many column names there are\n",
    "    num_col_passing = len(col_th_tag)\n",
    "\n",
    "    # list of column names\n",
    "    columns = []\n",
    "\n",
    "    for i in range(0, num_col_passing):\n",
    "        try:\n",
    "            data = col_th_tag[i].contents[0]\n",
    "            columns.append(data)\n",
    "        except:\n",
    "            columns.append('n/a') \n",
    "    \n",
    "    \n",
    "    ##rows\n",
    "    \n",
    "    rows_tr = rows_tbody.find_all('tr')\n",
    "    \n",
    "    num_index = len(rows_tbody.find_all('th'))\n",
    "    num_rows = len(rows_tr[0].find_all('td'))\n",
    "    \n",
    "    \n",
    "    row_data = []\n",
    "\n",
    "    for i in range(0, num_index):\n",
    "        row_td = rows_tr[i].find_all('td')\n",
    "    \n",
    "        data = []\n",
    "\n",
    "        for c in range(0, num_rows):\n",
    "            \n",
    "            try:\n",
    "                if len(row_td[c].find_all('a')) > 0:\n",
    "            \n",
    "                    d = row_td[c].find_all('a')[0].contents[0]\n",
    "                    data.append(d)\n",
    "                \n",
    "                else:\n",
    "                    d = row_td[c].contents[0]\n",
    "                    data.append(d)\n",
    "            \n",
    "            except:\n",
    "                data.append('n/a')\n",
    "        \n",
    "\n",
    "        row_data.append(data)\n",
    "        \n",
    "        \n",
    "    #index\n",
    "    index = []\n",
    "    for i in range(0, num_index):\n",
    "    \n",
    "        try:\n",
    "            data = rows_tbody.find_all('th')[i].contents[0]\n",
    "            index.append(data)\n",
    "        except:\n",
    "            index.append('n/a')\n",
    "        \n",
    "        \n",
    "    #insert index to each row to be equal to all columns\n",
    "    for i in range(0, len(index)):\n",
    "        row_data[i].insert(0, index[i])\n",
    "    \n",
    "    df = pd.DataFrame(index=index, data=row_data, columns=columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550a53c",
   "metadata": {},
   "source": [
    "# Fix Column Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "241eec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names and addd team name column\n",
    "def fix_col_labels(table_df_li: list, team: str):\n",
    "    \n",
    "    \n",
    "    #Team Stats and Ranking\n",
    "    table_df_li[0].columns = [\n",
    "        'Player', 'Points Scored by Team', 'Total Yds and TO', 'Offensive Plays: Pass Attempts + Rush Attempts + Times Sacked', \n",
    "        'Yards per Offensive Play', 'Team Turnovers Lost', 'Fumbles Lost by Player or Team', '1stD', \n",
    "        'Passes Completed', 'Passes Attempted', 'Yards Gained by Passing', 'Passing Touchdowns', \n",
    "        'Interceptions Thrown', 'Net Yards Gained per Pass Attempt', 'First Downs by Passing',\n",
    "        'Rushing Attempts', 'Rushing Yards', 'Rushing Touchdowns', 'Rushing Yards per Attempt', \n",
    "        'First Downs by Rushing', 'Penalties committed by Team and Accepted','Penalties in Yards Committed by Team', \n",
    "        'First Downs by Penalty', 'Number of Drives', 'Per. of Drives Ending in an Offensive Score',\n",
    "        'Per. of Drives Ending in an Offensive Turnover', 'Average Starting Field Position', 'Average Time per Drive', \n",
    "        'Average # of Plays per Drive', 'Net Yards per Drive', 'Average Points Scored per Drive'\n",
    "    ]\n",
    "    \n",
    "    #Schedule and Game Results\n",
    "    \n",
    "        #fix col to names\n",
    "    try:\n",
    "        table_df_li[1].columns = ['Week', 'Day', 'Date', 'Time', 'n/a', 'Win/Loss', 'Overtime', 'Team Record', 'Home/Away',\n",
    "                              'Opponent', 'Points Scored', 'Points Allowed', 'Offense 1st Down', 'Total Yards Gained of Offense', 'Total yards Gained by Passing',\n",
    "                              'Total Yards Gained by Rushing', 'Offense Turnovers', 'Defense 1st Down', 'Total Yards Allowed by Defense',\n",
    "                              'Total Passing Yards Allowed by Defense', 'Total Rushing Yards Allowed by Defense', 'Defense Turnovers', \n",
    "                              'Offense', 'Defense', 'Sp. Tms'\n",
    "                                 ]\n",
    "\n",
    "        table_df_li[1].drop(columns=['n/a'], inplace=True)\n",
    "\n",
    "        \n",
    "    except:        \n",
    "        table_df_li[1].columns = ['Week', 'Day', 'Date', 'Time', 'Win/Loss', 'Overtime', 'Team Record', 'Home/Away',\n",
    "                              'Opponent', 'Points Scored', 'Points Allowed', 'Offense 1st Down', 'Total Yards Gained of Offense', 'Total yards Gained by Passing',\n",
    "                              'Total Yards Gained by Rushing', 'Offense Turnovers', 'Defense 1st Down', 'Total Yards Allowed by Defense',\n",
    "                              'Total Passing Yards Allowed by Defense', 'Total Rushing Yards Allowed by Defense', 'Defense Turnovers', \n",
    "                              'Offense', 'Defense', 'Sp. Tms'\n",
    "                                 ]\n",
    "        # home/away games rows\n",
    "    table_df_li[1].iloc[:, 7] = ['away' if r == '@' else 'home' for r in table_df_li[1].iloc[:, 7]]          \n",
    "\n",
    "    \n",
    "    #Team Conversions\n",
    "    table_df_li[2].columns = [\n",
    "        'Player', '3rd Down Attempts in Game', '3rd Down Conversions', '3rd Down Conversion Per.', '4th Down Attempts in Game',\n",
    "        '4th Down Conversions in Game', '4th Down Conversion Per.', 'Red Zone Attempts', 'Touchdowns Scored After the Team Entered the Red Zone', \n",
    "        'Per. of the Time a Team Reaches the Red Zone and Scores a Touchdown'\n",
    "    ]\n",
    "\n",
    "    \n",
    "    #Passing\n",
    "    table_df_li[3].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started as an Offensive or Defensive Player', \n",
    "        'Team Record in Games Stareted by This QB', 'Passes Completed', 'Passes Attemped', 'Per. of Passes Completed', \n",
    "        'Yards Gained by Passing', 'Passing Touchdowns', 'Per. of Touchdowns Thrown when Attempting to Pass', 'Interceptions Thrown',\n",
    "        'Per. of Times Interceped when Attempting to Pass', 'First Downs Passing', 'Passing Success Rate', 'Longest Completed Pass Thrown',\n",
    "        'Yards Gained per Pass Attempt', 'Adjusted Yards gained per Pass Attempt', 'Yards Gained per Pass Completion', \n",
    "        'Yards Gained per Game Played', 'QB Rating', 'ESPN QB Rating', 'Times Sacked', 'Yards Lost due to Sacks', \n",
    "        'Per. of Time Sacked when Attempting to Pass', 'Net Yards Gained per Pass Attempt', 'Adjsuted Net Yards per Pass Attempt',\n",
    "        'Comebacks led by QB', 'Game-winning Drives led by QB'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    #Rushing and Receiving\n",
    "    table_df_li[4].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started as an Offensive or Defensive Player', 'Rushing Attempts',\n",
    "        'Rushing Yards Gained', 'Rushing Touchdown', 'First Downs Rushing', 'Rushing Success Rate', 'Longest Rushing Attempt', \n",
    "        'Rushing Yards per Attempt', 'Rushing Yards per Game', 'Rushing Attempts per Game', 'Pass Targets', 'Receptions', 'Receiving Yards',\n",
    "        'Receiving Yards per Reception', 'Receiving Touchdowns', 'First Downs Receiving', 'Receiving Success Rate', 'Longest Reception', \n",
    "        'Receptions per Game', 'Receiving Yards per Game', 'Catch Per.', 'Receiving Yards per Target', 'Touches: Rushing Attempts and Receptions',\n",
    "        'Scrimmage Yards per Touch: Rushing + Receiving Yardage per Opportunity', 'Yards from Scrimmage: Receiving and Rushing Yards', \n",
    "        'Rushing and Receiving Touchdowns', 'Lost and Recovered Fumbles'\n",
    "    ]\n",
    "    \n",
    "    #kick and punt returns\n",
    "    table_df_li[5].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started', 'Punts Returned',\n",
    "        'Punts Return Yardage', 'Punts Returned for Touchdown', 'Longest Punt Return', \n",
    "        'Yards per Punt Return', 'Kickoff Returns', 'Yardage for Kickoffs Returned', \n",
    "        'Kickoffs Returned for a Touchdown', 'Longest Kickoff Return', 'Yards per Kickoff Return',\n",
    "        'All-purpose Yards'\n",
    "    ]\n",
    "    \n",
    "    #Kicking\n",
    "    \n",
    "    table_df_li[6].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started', \n",
    "        'FGA 0-19', 'FGM 0-19', 'FGA 20-29', 'FGM 20-29', 'FGA 30-39', 'FGM 30-39',\n",
    "        'FGA 40-49', 'FGM 40-49', 'FGA 50+', 'FGM 50+', 'Field Goals Attempted', 'Field Goals Made',\n",
    "        'Longest Field Goal Made', 'Per. of Field Goals Made', 'Extra Points Attempted', 'Extra Points Made',\n",
    "        'Extra Point Per.', 'Kickoffs', 'Kickoff Yards', 'Kickoff Touchbacks', \n",
    "        'Per. Kickoff was a Touchback', 'Kickoff Average Yardage'\n",
    "        \n",
    "\n",
    "    ]\n",
    "    \n",
    "    #Punting\n",
    "    table_df_li[7].columns = [\n",
    "        'No.', 'Player', 'Age', 'Pos', 'Games Played', 'Games Started', 'Times Puned',\n",
    "        'Total Punt Yardage', 'Yards per Punt', 'Punt Return Yardage by Opposition', \n",
    "        'Punt Net yards', 'Punt Net Yards per Punt', 'Longest Punt', \n",
    "        'Punts Resulting in a Touchback', 'Per. of Punts Resulting in a Touchback', \n",
    "        'Punts Inside Opp. 20 Yard Line', 'Per. of Punts Downed Inside Opp. 20 Yard Line',\n",
    "        'Times Punts Blocked'\n",
    "    ]\n",
    "    \n",
    "    #defense and fumbles\n",
    "    table_df_li[8].columns = [\n",
    "        'No.','Player', 'Age', 'Pos', 'Games Played', 'Games Started', 'Passes Intercepted on Defense',\n",
    "        'Yards Interceptions were Returned', 'Interceptions Returned for Touchdowns', \n",
    "        'Longest Interception Return', 'Passes Defended by Defensive Player', '# Forced Fumble by Opp.', \n",
    "        '# Fumbled both Lost and Recovered by Own Team', 'Fumbles Recovered by Original Fumbler', \n",
    "        'Yards Recovered Fumbles were Returned', 'Fumbles Recovered for Touchdown', 'Sacks', \n",
    "        'Tackles Solo+Assisted', 'Solo Tackles', 'Assisted Tackles', 'Tackles for Loss', \n",
    "        'Quarterback Hits', 'Safeties Scored by Player/Team'\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    #Scoring Summary\n",
    "    table_df_li[9].columns = [\n",
    "         'No.','Player', 'Age', 'Pos', 'Games Played', 'Games Started', 'Rush TD', 'Reception TD', \n",
    "        'Punt Return TD', 'Kick Return TD', 'Fumble Return TD', 'Interception TD', 'Other TD', \n",
    "        'All Touchdown Scored', '2-Point Conversions Made', 'Two-Point Conversions Attempted', \n",
    "        'Defensive Two-Point Conversions', 'Extra Points Made', 'Extra Points Allowed', 'Field Goals Made',\n",
    "        'Field Goals Attempted', 'Safeties Scored by Player/Team', 'Total Points Scored by all Means',\n",
    "        'Poins per Game'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        #touchdown log\n",
    "        table_df_li[10].drop(columns=['n/a'], inplace=True)\n",
    "    \n",
    "        #opponenet touchdown log\n",
    "        table_df_li[11].drop(columns=['n/a'], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #touchdown log\n",
    "    table_df_li[10].columns = [\n",
    "        'Rank','Date', 'Opponent', 'Results', 'Quarter', 'Distance', 'Type', 'Detail'\n",
    "    ]\n",
    "    \n",
    "        #opponent touchdown log\n",
    "    table_df_li[11].columns = [\n",
    "        'Rank','Date', 'Opponent', 'Results', 'Quarter', 'Distance', 'Type', 'Detail'\n",
    "    ]\n",
    "\n",
    "    #insert team name column to each row\n",
    "    for i in range(0, len(table_df_li)):\n",
    "        \n",
    "        num_rows = len(table_df_li[i].values)\n",
    "\n",
    "        \n",
    "        table_df_li[i]['Team'] = [team] * len(table_df_li[i])\n",
    "    \n",
    "    return table_df_li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db9f0f10-eb8e-4879-8049-786773df0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix inconsistent data types between similar tables\n",
    "# make all columns in tables the same\n",
    "##################################################     decorator????     ####################################\n",
    "def fix_col_dtypes (table_df_li: list, team: str):\n",
    "\n",
    "    #Team Stats and Rankings\n",
    "    df = table_df_li[0]\n",
    "\n",
    "    dtypes_li = ['object', 'int64', 'int64', 'int64', 'float64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'float64', 'int64', 'int64', 'int64', 'int64', 'float64', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'int64', 'float64', 'float64', 'object', 'object', 'float64', 'float64', \n",
    "                 'float64', 'object']\n",
    "        \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "            \n",
    "    table_df_li[0] = df\n",
    "\n",
    "    \n",
    "    #Schedule and Game Results\n",
    "    df = table_df_li[1] \n",
    "    dtypes_li = ['int64','object', 'object', 'object', 'object', 'int64', 'object', 'object', 'object', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'float64', 'float64', 'float64', 'object']\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df['Points Scored'].iloc[i].isnumeric() == False:\n",
    "                replace_value = df['Points Scored'].iloc[i]\n",
    "                df[df['Points Scored'] == replace_value] = 0\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df['Overtime'] = df['Overtime'].fillna(0)\n",
    "    df['Overtime'] = df['Overtime'].replace('OT', 1)\n",
    "\n",
    "    df['Week'] = range(1, len(df)+1)\n",
    "\n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[1] = df\n",
    "\n",
    "    \n",
    "    #Team Conversions\n",
    "    df = table_df_li[2] \n",
    "    \n",
    "    try:    \n",
    "        df['3rd Down Conversion Per.'] = df['3rd Down Conversion Per.'].str.strip('%')\n",
    "        df['4th Down Conversion Per.'] = df['4th Down Conversion Per.'].str.strip('%')\n",
    "        df['Per. of the Time a Team Reaches the Red Zone and Scores a Touchdown'] = \\\n",
    "        df['Per. of the Time a Team Reaches the Red Zone and Scores a Touchdown'].str.strip('%')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    dtypes_li = ['object', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', \n",
    "                 'float64', 'object']\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[2] = df\n",
    "\n",
    "    \n",
    "    #Passing\n",
    "    df = table_df_li[3]\n",
    "    \n",
    "    dtypes_li = ['object', 'object', 'int64', 'object', 'int64', 'int64', 'object', 'int64', 'int64', \n",
    "                 'float64', 'int64', 'int64', 'float64', 'int64', 'float64', 'int64', 'float64', \n",
    "                 'int64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', \n",
    "                 'int64', 'int64', 'float64', 'float64', 'float64', 'int64', 'int64', 'object']\n",
    "        \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[3] = df\n",
    "\n",
    "    \n",
    "    #Rushing and Receiving\n",
    "    df = table_df_li[4]\n",
    "    \n",
    "    dtypes_li = ['object', 'object', 'int64', 'object', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'float64', 'int64', 'float64', 'float64', 'float64', 'int64', 'int64', 'int64', 'float64','int64', \n",
    "                 'int64', 'float64', 'int64', 'float64', 'float64', 'float64', 'float64', 'int64', 'float64','int64',\n",
    "                 'int64', 'int64', 'object']\n",
    "\n",
    "    df['Catch Per.'] = df['Catch Per.'].str.strip('%')\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[4] = df\n",
    "\n",
    "    \n",
    "    #kick and punt returns\n",
    "    df = table_df_li[5]\n",
    "    \n",
    "    dtypes_li = ['object', 'object', 'int64', 'object', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'float64', 'int64', 'int64', 'int64', 'int64', 'float64', 'int64', 'object']\n",
    "\n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[5] = df\n",
    "\n",
    "    \n",
    "    #Kicking                         \n",
    "    df = table_df_li[6] \n",
    "\n",
    "    df['FGA 0-19'] = df['FGA 0-19'].fillna(0)\n",
    "    df['FGA 20-29'] = df['FGA 20-29'].fillna(0)\n",
    "    df['FGA 30-39'] = df['FGA 30-39'].fillna(0)\n",
    "    df['FGA 40-49'] = df['FGA 40-49'].fillna(0)\n",
    "    df['FGA 50+'] = df['FGA 50+'].fillna(0)\n",
    "\n",
    "    df['FGM 0-19'] = df['FGM 0-19'].fillna(0)\n",
    "    df['FGM 20-29'] = df['FGM 20-29'].fillna(0)\n",
    "    df['FGM 30-39'] = df['FGM 30-39'].fillna(0)\n",
    "    df['FGM 40-49'] = df['FGM 40-49'].fillna(0)\n",
    "    df['FGM 50+'] = df['FGM 50+'].fillna(0)\n",
    "\n",
    "    df['Field Goals Attempted'] = df['Field Goals Attempted'].fillna(0)\n",
    "    df['Field Goals Made'] = df['Field Goals Made'].fillna(0)\n",
    "    df['Longest Field Goal Made'] = df['Longest Field Goal Made'].fillna(0)\n",
    "    \n",
    "    df['Per. of Field Goals Made'] = df['Per. of Field Goals Made'].str.strip('%') \n",
    "    df['Per. of Field Goals Made'] = df['Per. of Field Goals Made'].fillna(0)\n",
    "\n",
    "    df['Extra Points Attempted'] = df['Extra Points Attempted'].fillna(0)\n",
    "    df['Extra Points Made'] = df['Extra Points Made'].fillna(0)\n",
    "\n",
    "    df['Extra Point Per.'] = df['Extra Point Per.'].str.strip('%')\n",
    "    df['Extra Point Per.'] = df['Extra Point Per.'].fillna(0)\n",
    "\n",
    "    df['Kickoffs'] = df['Kickoffs'].fillna(0)\n",
    "    df['Kickoff Yards'] = df['Kickoff Yards'].fillna(0)\n",
    "\n",
    "    df['Kickoff Touchbacks'] = df['Kickoff Touchbacks'].fillna(0)\n",
    "\n",
    "    df['Per. Kickoff was a Touchback'] = df['Per. Kickoff was a Touchback'].str.strip('%')\n",
    "    df['Per. Kickoff was a Touchback'] = df['Per. Kickoff was a Touchback'].fillna(0)\n",
    "\n",
    "    df['Kickoff Average Yardage'] = df['Kickoff Average Yardage'].fillna(0)\n",
    "    \n",
    "    dtypes_li = ['int64', 'object', 'int64', 'object', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', \n",
    "                 'int64', 'int64', 'float64','int64', 'int64', 'int64', 'float64', 'float64', 'object']\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[6] = df\n",
    "\n",
    "    \n",
    "    #Punting\n",
    "    df = table_df_li[7]\n",
    "\n",
    "    dtypes_li = ['object', 'object', 'int64', 'object', 'int64', 'int64', 'int64', 'int64', 'float64', 'int64',\n",
    "                 'int64', 'float64', 'int64', 'int64', 'float64', 'int64', 'float64', 'int64', 'object']\n",
    "    \n",
    "    df['Per. of Punts Resulting in a Touchback'] = df['Per. of Punts Resulting in a Touchback'].str.strip('%')\n",
    "    df['Per. of Punts Downed Inside Opp. 20 Yard Line'] = df['Per. of Punts Downed Inside Opp. 20 Yard Line'].str.strip('%')\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[7] = df\n",
    "\n",
    "    \n",
    "    #defense and fumbles\n",
    "    df = table_df_li[8]\n",
    "    \n",
    "    dtypes_li = ['object', 'object', 'int64', 'object', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'object']\n",
    "\n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[8] = df\n",
    "\n",
    "    \n",
    "    #Scoring Summary\n",
    "    df = table_df_li[9]\n",
    "\n",
    "    dtypes_li = ['object', 'object', 'int64', 'object', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', \n",
    "                 'int64', 'object', 'int64', 'float64', 'object']\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[9] = df\n",
    "    \n",
    "\n",
    "    #Touchdown Log\n",
    "    df = table_df_li[10]\n",
    "\n",
    "    dtypes_li = ['object', 'object', 'object', 'object', 'object', 'int64', 'object', 'object', 'object']\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[10] = df\n",
    "\n",
    "    \n",
    "    #Opponent\n",
    "    df = table_df_li[11]\n",
    "    \n",
    "    dtypes_li = ['object', 'object', 'object', 'object', 'object', 'int64', 'object', 'object', 'object']\n",
    "    \n",
    "    for col, dtype in zip(df.columns,dtypes_li):\n",
    "        try:\n",
    "            df[col] = df[col].replace('n/a', 0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except:\n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        finally:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "\n",
    "    table_df_li[11] = df\n",
    "\n",
    "    \n",
    "    return table_df_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69d22b1d-abd3-473f-b261-204686b22200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert time to 24 hours\n",
    "def convert_to_24hour(time_str):\n",
    "    hour, minute, am_pm = re.findall('\\d+|\\w+', time_str)\n",
    "    hour = int(hour)\n",
    "    if am_pm == 'PM' and hour != 12:\n",
    "        hour += 12\n",
    "    elif am_pm == 'AM' and hour == 12:\n",
    "        hour = 0\n",
    "    return f'{hour:02d}:{minute}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2e341d-6c72-4f4a-bbe4-3043ad15bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix data columns, splits, dates, feature engineering\n",
    "\n",
    "def fix_data(table_df_li: list, team: str):\n",
    "    #team_stats_and_ranking - ok\n",
    "\n",
    "    #schedule_and_game_results\n",
    "        #delete extra rows\n",
    "    df = table_df_li[1]\n",
    "    \n",
    "    df = df[df['Team'] != 0]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "        #fix time\n",
    "    time_dict = {'Time': []}\n",
    "    fixed_date_dict = {'Date': []}\n",
    "    for i in df.index:\n",
    "        try:\n",
    "            time_dict['Time'].append(convert_to_24hour(df['Time'].iloc[i]))\n",
    "        except:\n",
    "            time_dict['Time'].append('nan')\n",
    "\n",
    "        try:\n",
    "            if ('January' in df['Date'].iloc[i]) or ('February' in df['Date'].iloc[i]):\n",
    "                mon_day = df['Date'].iloc[i]\n",
    "                y = df['Year'].iloc[i]+1\n",
    "            \n",
    "                date = mon_day +' '+ str(y)\n",
    "                \n",
    "                dt = datetime.strptime(date, '%B %d %Y')\n",
    "            \n",
    "                fixed_date = datetime.strftime(dt, format='%m/%d/%Y')\n",
    "        \n",
    "                fixed_date = datetime.strptime(fixed_date, '%m/%d/%Y')\n",
    "        \n",
    "            \n",
    "                fixed_date_dict['Date'].append(fixed_date)\n",
    "                \n",
    "            else:\n",
    "                mon_day = df['Date'].iloc[i]\n",
    "                y = df['Year'].iloc[i]\n",
    "            \n",
    "                date = mon_day +' '+ str(y)\n",
    "                \n",
    "                dt = datetime.strptime(date, '%B %d %Y')\n",
    "            \n",
    "                fixed_date = datetime.strftime(dt, format='%m/%d/%Y')\n",
    "        \n",
    "                fixed_date = datetime.strptime(fixed_date,'%m/%d/%Y')\n",
    "        \n",
    "            \n",
    "                fixed_date_dict['Date'].append(fixed_date)\n",
    "    \n",
    "        except:\n",
    "            fixed_date = 'nan'\n",
    "            fixed_date_dict['Date'].append(fixed_date)\n",
    "\n",
    "    \n",
    "    df['Time'] = time_dict['Time']\n",
    "    df['Date'] = fixed_date_dict['Date']\n",
    "\n",
    "    df['Win/Loss'] = df['Win/Loss'].replace('L', 'Loss')\n",
    "    df['Win/Loss'] = df['Win/Loss'].replace('W', 'Win')\n",
    "\n",
    "    table_df_li[1] = df\n",
    "\n",
    "    #team_conversions - ok\n",
    "\n",
    "    #passing - ok\n",
    "\n",
    "    #rushing_and_receiving - ok\n",
    "\n",
    "    #kick_and_punt_returns - ok\n",
    "\n",
    "    #kicking - ok\n",
    "\n",
    "    #punting - ok\n",
    "\n",
    "    #defense_and_fumbles - ok\n",
    "\n",
    "    #scoring_summary - ok\n",
    "\n",
    "    \n",
    "    #touchdown_log\n",
    "    df = table_df_li[10]\n",
    "\n",
    "    win_loss_li = []\n",
    "    home_score_li = []\n",
    "    opp_score_li = []\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        try:\n",
    "            df_res_split = df['Results'].iloc[i].split(',')\n",
    "    \n",
    "            if df_res_split[0] == 'L':\n",
    "                win_loss = df_res_split[0].replace('L', 'Loss')\n",
    "                win_loss_li.append(win_loss)\n",
    "\n",
    "            else:\n",
    "                win_loss = df_res_split[0].replace('W', 'Win')\n",
    "                win_loss_li.append(win_loss)\n",
    "\n",
    "            hs, os = df_res_split[1].split('-')\n",
    "\n",
    "            hs = hs.strip()\n",
    "            os = os.strip()\n",
    "\n",
    "            home_score_li.append(hs)\n",
    "            opp_score_li.append(os)\n",
    "        \n",
    "        except:\n",
    "            win_loss_li.append('nan')\n",
    "            home_score_li.append('nan')\n",
    "            opp_score_li.append('nan')\n",
    "\n",
    "    df['Win/Loss'] = win_loss_li\n",
    "    df['Home_Score'] = home_score_li\n",
    "    df['Opponenet_Score'] = opp_score_li\n",
    "\n",
    "    df = df.drop(columns=['Results'])\n",
    "\n",
    "    df = df[['Rank', 'Team', 'Date', 'Opponent', 'Win/Loss', 'Home_Score', 'Opponenet_Score', 'Quarter', 'Distance', 'Type', 'Detail']]\n",
    "\n",
    "    table_df_li[10] = df\n",
    "    \n",
    "\n",
    "    #opponent touchdown log\n",
    "    df = table_df_li[11]\n",
    "\n",
    "    win_loss_li = []\n",
    "    home_score_li = []\n",
    "    opp_score_li = []\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        try:\n",
    "            df_res_split = df['Results'].iloc[i].split(',')\n",
    "    \n",
    "            if df_res_split[0] == 'L':\n",
    "                win_loss = df_res_split[0].replace('L', 'Loss')\n",
    "                win_loss_li.append(win_loss)\n",
    "\n",
    "            else:\n",
    "                win_loss = df_res_split[0].replace('W', 'Win')\n",
    "                win_loss_li.append(win_loss)\n",
    "                \n",
    "            hs, os = df_res_split[1].split('-')\n",
    "\n",
    "            hs = hs.strip()\n",
    "            os = os.strip()\n",
    "\n",
    "            home_score_li.append(hs)\n",
    "            opp_score_li.append(os)\n",
    "        \n",
    "        except:\n",
    "            win_loss_li.append('nan')\n",
    "            home_score_li.append('nan')\n",
    "            opp_score_li.append('nan')\n",
    "            \n",
    "\n",
    "    df['Win/Loss'] = win_loss_li\n",
    "    df['Home_Score'] = home_score_li\n",
    "    df['Opponenet_Score'] = opp_score_li\n",
    "\n",
    "    df = df.drop(columns=['Results'])\n",
    "\n",
    "    df = df[['Rank','Team', 'Date', 'Opponent', 'Win/Loss', 'Home_Score', 'Opponenet_Score', 'Quarter', 'Distance', 'Type', 'Detail']]\n",
    "\n",
    "\n",
    "    table_df_li[11] = df\n",
    "\n",
    "    \n",
    "    return table_df_li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89440040",
   "metadata": {},
   "source": [
    "# Final Save CSV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77a9e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_create_dataframes_save_csv(team: str, year: int):    \n",
    "    \n",
    "    team_to_url_df = pd.DataFrame(\n",
    "        data=[\n",
    "            [\n",
    "                'crd', #Cardinals\n",
    "                'atl', #Falcons\n",
    "                'rav', #Ravens\n",
    "                'buf', #Bills\n",
    "                'car', #Panthers\n",
    "                'chi', #Bears\n",
    "                'cin', #Bengals\n",
    "                'cle', #Browns\n",
    "                'dal', #Cowboys\n",
    "                'den', #Broncos\n",
    "                'det', #Lions\n",
    "                'gnb', #Packers\n",
    "                'htx', #Texans\n",
    "                'clt', # Colts\n",
    "                'jax', #Jaguars\n",
    "                'kan', #Chiefs\n",
    "                'rai', #Raiders\n",
    "                'sdg', #Chargers\n",
    "                'ram', #Rams\n",
    "                'mia', #Dolphins\n",
    "                'min', #Vikings\n",
    "                'nwe', #Patriots\n",
    "                'nor', #Saints\n",
    "                'nyg', #Giants\n",
    "                'nyj', #Jets\n",
    "                'phi', #Eagles\n",
    "                'pit', #Steelers\n",
    "                'sfo', #49ers\n",
    "                'sea', #Seahawks\n",
    "                'tam', #Buccaneers\n",
    "                'oti', #Titans\n",
    "                'was' #Commanders\n",
    "            ]\n",
    "        ], \n",
    "        columns=[\n",
    "            'Cardinals',\n",
    "            'Falcons',\n",
    "            'Ravens',\n",
    "            'Bills',\n",
    "            'Panthers',\n",
    "            'Bears',\n",
    "            'Bengals',\n",
    "            'Browns',\n",
    "            'Cowboys',\n",
    "            'Broncos',\n",
    "            'Lions',\n",
    "            'Packers',\n",
    "            'Texans',\n",
    "            'Colts',\n",
    "            'Jaguars',\n",
    "            'Chiefs',\n",
    "            'Raiders',\n",
    "            'Chargers',\n",
    "            'Rams',\n",
    "            'Dolphins',\n",
    "            'Vikings',\n",
    "            'Patriots',\n",
    "            'Saints',\n",
    "            'Giants',\n",
    "            'Jets',\n",
    "            'Eagles',\n",
    "            'Steelers',\n",
    "            '49ers',\n",
    "            'Seahawks',\n",
    "            'Buccaneers',\n",
    "            'Titans',\n",
    "            'Commanders'\n",
    "        ])\n",
    "    \n",
    "    # string url\n",
    "    str_url = 'https://www.pro-football-reference.com/teams/{}/{}.htm'\n",
    "\n",
    "    #get team url ID\n",
    "    team_url_str = team_to_url_df[team].values[0]\n",
    "    \n",
    "    # URL\n",
    "    url = str_url.format(team_url_str, year)\n",
    "    \n",
    "    # request html text\n",
    "    tables_html_request = tables_html(url=url)\n",
    "    \n",
    "    # delay execute so not to trigger ip address block\n",
    "    time.sleep(random.randrange(7,9))\n",
    "    \n",
    "    # webscrape tables/ create dataframes\n",
    "    \n",
    "    # table name list with team and year to format\n",
    "    table_name_li = [\n",
    "        'team_stats_and_ranking_{}_{}',\n",
    "        'schedule_and_game_results_{}_{}',\n",
    "        'team_conversions_{}_{}',\n",
    "        'passing_{}_{}',\n",
    "        'rushing_and_receiving_{}_{}',\n",
    "        'kick_and_punt_returns_{}_{}',\n",
    "        'kicking_{}_{}',\n",
    "        'punting_{}_{}',\n",
    "        'defense_and_fumbles_{}_{}',\n",
    "        'scoring_summary_{}_{}',\n",
    "        'touchdown_log_{}_{}',\n",
    "        'opponent_touchdown_log_{}_{}'\n",
    "    ]\n",
    "    \n",
    "    #file location\n",
    "    file_loc = 'NFL_Data_{}/{}/'.format(year, team)\n",
    "    \n",
    "    table_num = 12\n",
    "\n",
    "    #put tables into a list\n",
    "    table_df_li = [webscrape_tables(tables=tables_html_request, table_num=i) for i in range(0,table_num)]\n",
    "\n",
    "    #use list of tabels to fix all the columns\n",
    "    table_df_li = fix_col_labels(table_df_li=table_df_li, team=team)\n",
    "    table_df_li = fix_col_dtypes(table_df_li=table_df_li, team=team)\n",
    "\n",
    "    #upload tables to csv file\n",
    "    for t in range(0, table_num):\n",
    "\n",
    "        #add the year to each row\n",
    "        table_df_li[t]['Year'] = [year] * len(table_df_li[t])\n",
    "\n",
    "    \n",
    "    #fix data on tables\n",
    "    table_df_li = fix_data(table_df_li=table_df_li, team=team)\n",
    "\n",
    "    #import to each year and team file\n",
    "    for t in range(0, table_num):   \n",
    "        table_df_li[t].to_csv(file_loc+table_name_li[t].format(team, year))\n",
    "        \n",
    "    return  table_df_li\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf287ad",
   "metadata": {},
   "source": [
    "# Download CSV Files from all teams 2010-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a12cf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2010,2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d54cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names=[\n",
    "    '49ers',\n",
    "    'Bears',\n",
    "    'Bengals',\n",
    "    'Broncos',\n",
    "    'Browns',\n",
    "    'Buccaneers',\n",
    "    'Bills',\n",
    "    'Cardinals',\n",
    "    'Chargers',\n",
    "    'Chiefs',\n",
    "    'Colts',\n",
    "    'Commanders',\n",
    "    'Cowboys',\n",
    "    'Dolphins',\n",
    "    'Eagles',\n",
    "    'Falcons',\n",
    "    'Giants',\n",
    "    'Jaguars',\n",
    "    'Jets',\n",
    "    'Lions',\n",
    "    'Packers',\n",
    "    'Panthers',\n",
    "    'Patriots',\n",
    "    'Raiders',\n",
    "    'Rams',\n",
    "    'Ravens',\n",
    "    'Saints',\n",
    "    'Seahawks',\n",
    "    'Steelers',\n",
    "    'Texans',\n",
    "    'Titans',\n",
    "    'Vikings'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d06ec2-d91e-416b-969d-4e8873fbfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_li = [\n",
    "    'team_stats_and_ranking_{}_{}',\n",
    "    'schedule_and_game_results_{}_{}',\n",
    "    'team_conversions_{}_{}',\n",
    "    'passing_{}_{}',\n",
    "    'rushing_and_receiving_{}_{}',\n",
    "    'kick_and_punt_returns_{}_{}',\n",
    "    'kicking_{}_{}',\n",
    "    'punting_{}_{}',\n",
    "    'defense_and_fumbles_{}_{}',\n",
    "    'scoring_summary_{}_{}',\n",
    "    'touchdown_log_{}_{}',\n",
    "    'opponent_touchdown_log_{}_{}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f366ad6b-338d-4b12-a415-8203ee55d91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7087f4-0f22-4103-9e1b-cfdb255c5c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bills 2010\n",
      "Bills 2011\n",
      "Bills 2012\n",
      "Bills 2013\n",
      "Bills 2014\n",
      "Bills 2015\n",
      "Bills 2016\n",
      "Bills 2017\n",
      "Bills 2018\n",
      "Bills 2019\n",
      "Bills 2020\n",
      "Bills 2021\n",
      "Bills 2022\n",
      "Bills 2023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#this will webscrape all the teams tables from 2010-2022\n",
    "#do not run \n",
    "###                         45-60 min run\n",
    "for year in years:\n",
    "    for team in team_names:\n",
    "        print(team, year)\n",
    "        webscrape_create_dataframes_save_csv(team=team, year=year)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303a4d3-f50e-4337-ada7-e19c4e7b9b35",
   "metadata": {},
   "source": [
    "#for current year\n",
    "for year in [2023]:\n",
    "    for team in team_names:\n",
    "        webscrape_create_dataframes_save_csv(team=team, year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6662d62-483c-4577-bbc1-42596ff6c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('NFL_Data_2010/49ers/schedule_and_game_results_49ers_2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1ef99-c37b-4073-b541-b4b841214ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
