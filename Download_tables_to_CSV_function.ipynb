{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42a90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224da9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is grabing the Cardinals html web page\n",
    "#url = 'https://www.pro-football-reference.com/teams/sfo/2022.htm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360332a3",
   "metadata": {},
   "source": [
    "# Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fdaca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function before creating tables\n",
    "def tables_html(url:str):\n",
    "    html = requests.get(url).text\n",
    "    \n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    tables = soup.find_all(class_='table_wrapper')\n",
    "    \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec84d2e",
   "metadata": {},
   "source": [
    "# DF Columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873c01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_columns (tables:str, table_num:int):\n",
    "\n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "    \n",
    "    \n",
    "    #find thead tag to isolate col names\n",
    "    table_html = table_html.find_all('thead')[0]\n",
    "\n",
    "    # find class_ = 'poptip' to isolate col names\n",
    "    col_th_tag = table_html.find_all(class_='poptip')\n",
    "\n",
    "    # get how many column names there are\n",
    "    num_col_passing = len(col_th_tag)\n",
    "\n",
    "    # list of column names\n",
    "    columns = []\n",
    "\n",
    "    for i in range(0, num_col_passing):\n",
    "        try:\n",
    "            data = col_th_tag[i].contents[0]\n",
    "            columns.append(data)\n",
    "        except:\n",
    "            columns.append('n/a')   \n",
    "            \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e2645",
   "metadata": {},
   "source": [
    "# DF Rows!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7b3cd",
   "metadata": {},
   "source": [
    "## Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61c8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_index(tables:str, table_num:int):\n",
    "    \n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "\n",
    "    rows_tbody = table_html.find_all('tbody')[0]\n",
    "    \n",
    "       \n",
    "    #get index\n",
    "    num_index = len(rows_tbody.find_all('th'))\n",
    "    \n",
    "    index = []\n",
    "    for i in range(0, num_index):\n",
    "    \n",
    "        try:\n",
    "            data = rows_tbody.find_all('th')[i].contents[0]\n",
    "            index.append(data)\n",
    "        except:\n",
    "            index.append('n/a')\n",
    "        \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e3a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_rows(tables:str, table_num:int):\n",
    "    \n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "\n",
    "    rows_tbody = table_html.find_all('tbody')[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    rows_tr = rows_tbody.find_all('tr')\n",
    "    \n",
    "    num_index = len(rows_tbody.find_all('th'))\n",
    "    num_rows = len(rows_tr[0].find_all('td'))\n",
    "    \n",
    "    \n",
    "    row_data = []\n",
    "\n",
    "    for i in range(0, num_index):\n",
    "        row_td = rows_tr[i].find_all('td')\n",
    "    \n",
    "        data = []\n",
    "\n",
    "        for c in range(0, num_rows):\n",
    "            \n",
    "            try:\n",
    "                if len(row_td[c].find_all('a')) > 0:\n",
    "            \n",
    "                    d = row_td[c].find_all('a')[0].contents[0]\n",
    "                    data.append(d)\n",
    "                \n",
    "                else:\n",
    "                    d = row_td[c].contents[0]\n",
    "                    data.append(d)\n",
    "            \n",
    "            except:\n",
    "                data.append('n/a')\n",
    "        \n",
    "\n",
    "        row_data.append(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    index = []\n",
    "    for i in range(0, num_index):\n",
    "    \n",
    "        try:\n",
    "            data = rows_tbody.find_all('th')[i].contents[0]\n",
    "            index.append(data)\n",
    "        except:\n",
    "            index.append('n/a')\n",
    "        \n",
    "        \n",
    "    #insert index to each row to be equal to all columns\n",
    "    for i in range(0, len(index)):\n",
    "        row_data[i].insert(0, index[i])\n",
    "        \n",
    "        \n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550a53c",
   "metadata": {},
   "source": [
    "# Fix Column Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6180e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix defense and fumbles table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "241eec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_col_labels(table_df_li: list, team: str):\n",
    "    \n",
    "    \n",
    "    #Team Stats and Rankings\n",
    "    table_df_li[0].columns = [\n",
    "        'Player', 'Points Scored by Team', 'Total Yds and TO', 'Offensic Plays: Pass Attempts + Rush Attempts + Times Sacked', \n",
    "        'Yards per Offensive Play', 'Team Turnovers Lost', 'Fumbles Lost by Player or Team', '1stD', 'Passes Completed', 'Passes Attempted', \n",
    "        'Yards Gained by Passing', 'Passing Touchdowns', 'Interceptions Thrown', 'Net Yards Gained per Pass Attempt', 'First Downs by Passing',\n",
    "        'Rushing Attempts', 'Rushing Yards', 'Rushin Touchdowns', 'Rushing Yards per Attempt', 'First Downs by Rushing', 'Penalties committed by Team and Accepted',\n",
    "        'Penalties in Yards Committed by Team', 'First Downs by Penalty', 'Number of Drives', '% of Drives Ending in an Offensive Score',\n",
    "        '% of Drives Ending in an Offensive Turnover', 'Average Starting Field Position', 'Average Time per Drive', 'Average # of Plays per Drive',\n",
    "        'Net Yards per Drive', 'Average Points Scored per Drive'\n",
    "    ]\n",
    "    \n",
    "    #Schedule and Game Results\n",
    "    \n",
    "        #fix col to names\n",
    "    try:\n",
    "        table_df_li[1].columns = ['Week', 'Day', 'Date', 'Time', 'n/a', 'Win/Loss', 'Overtime', 'Team Record', 'Home/Away',\n",
    "                              'Opponent', 'Points Scored', 'Points Allowed', 'Offense 1st Down', 'Total Yards Gained of Offense', 'Total yards Gained by Passing',\n",
    "                              'Total Yards Gained by Rushing', 'Offense Turnovers', 'Defense 1st Down', 'Total Yards Allowed by Defense',\n",
    "                              'Total Passing Yards Allowed by Defense', 'Total Rushing Yards Allowed by Defense', 'Defense Turnovers', \n",
    "                              'Offense', 'Defense', 'Sp. Tms']\n",
    "\n",
    "        table_df_li[1].drop(columns=['n/a'], inplace=True)\n",
    "\n",
    "        \n",
    "    except:        \n",
    "        table_df_li[1].columns = ['Week', 'Day', 'Date', 'Time', 'Win/Loss', 'Overtime', 'Team Record', 'Home/Away',\n",
    "                              'Opponent', 'Points Scored', 'Points Allowed', 'Offense 1st Down', 'Total Yards Gained of Offense', 'Total yards Gained by Passing',\n",
    "                              'Total Yards Gained by Rushing', 'Offense Turnovers', 'Defense 1st Down', 'Total Yards Allowed by Defense',\n",
    "                              'Total Passing Yards Allowed by Defense', 'Total Rushing Yards Allowed by Defense', 'Defense Turnovers', \n",
    "                              'Offense', 'Defense', 'Sp. Tms']\n",
    "        # home/away games rows\n",
    "    table_df_li[1].iloc[:, 7] = ['away' if r == '@' else 'home' for r in table_df_li[1].iloc[:, 7]]          \n",
    "\n",
    "    \n",
    "    #Team Conversions\n",
    "    table_df_li[2].columns = [\n",
    "        'Player', '3rd Down Attempts in Game', '3rd Down Conversions', '3rd Down Conversion %', '4th Down Attempts in Game',\n",
    "        '4th Down Conversions in Game', '4th Down Conversion %', 'Red Zone Attempts', 'Touchdowns Scored After the Team Entered the Red Zone', \n",
    "        '% of the Time a Team Reaches the Red Zone and Scores a Touchdown', \n",
    "    ]\n",
    "\n",
    "    \n",
    "    #Passing\n",
    "    table_df_li[3].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started as an Offensive or Defensive Player', \n",
    "        'Team Record in Games Stareted by This QB', 'Passes Completed', 'Passes Attemped', '% of Passes Completed', \n",
    "        'Yards Gained by Passing', 'Passing Touchdowns', '% of Touchdowns Thrown when Attempting to Pass', 'Interceptions Thrown',\n",
    "        '% of Times Interceped when Attempting to Pass', 'First Downs Passing', 'Passing Success Rate', 'Longest Completed Pass Thrown',\n",
    "        'Yards Gained per Pass Attempt', 'Adjusted Yards gained per Pass Attempt', 'Yards Gained per Pass Completion', \n",
    "        'Yards Gained per Game Played', 'QB Rating', 'ESPN QB Rating', 'Times Sacked', 'Yards Lost due to Sacks', \n",
    "        '% of Time Sacked when Attempting to Pass', 'Net Yards Gained per Pass Attempt', 'Adejsuted Net Yards per Pass Attempt',\n",
    "        'Comebacks led by QB', 'Game-winning Drives led by QB'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    #Rushing and Receiving\n",
    "    table_df_li[4].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started as an Offensive or Defensive Player', 'Rushing Attempts',\n",
    "        'Rushing Yards Gained', 'Rushing Touchdown', 'First Downs Rushing', 'Rushing Success Rate', 'Longest Rushing Attempt', \n",
    "        'Rushing Yards per Attempt', 'Rushing Yards per Game', 'Rushing Attempts per Game', 'Pass Targets', 'Receptions', 'Receiving Yards',\n",
    "        'Receiving Yards per Reception', 'Receiving Touchdowns', 'First Downs Receiving', 'Receiving Success Rate', 'Longest Reception', \n",
    "        'Receptions per Game', 'Receiving Yards per Game', 'Catch%', 'Receiving Yards per Target', 'Touches: Rushing Attempts and Receptions',\n",
    "        'Scrimmage Yards per Touch: Rushing + Receiving Yardage per Opportunity', 'Yards from Scrimmage: Receiving and Rushing Yards', \n",
    "        'Rushing and Receiving Touchdowns', 'Lost and Recovered Fumbles'\n",
    "    ]\n",
    "    \n",
    "    #kick and punt returns\n",
    "    table_df_li[5].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started', 'Punts Returned',\n",
    "        'Punts Return Yardage', 'Punts Returned for Touchdown', 'Longest Punt Return', \n",
    "        'Yards per Punt Return', 'Kickoff Returns', 'Yardage for Kickoffs Returned', \n",
    "        'Kickoffs Returned for a Touchdown', 'Longest Kickoff Return', 'Yards per Kickoff Return',\n",
    "        'All-purpose Yards'\n",
    "    ]\n",
    "    \n",
    "    #Kicking\n",
    "    \n",
    "    table_df_li[6].columns = [\n",
    "        'No.', 'Player', 'Age', 'Position', 'Games Played', 'Games Started', \n",
    "        'FGA 0-19', 'FGM 0-19', 'FGA 20-29', 'FGM 20-29', 'FGA 30-39', 'FGM 30-39',\n",
    "        'FGA 40-49', 'FGM 40-49', 'FGA 50+', 'FGM 50+', 'Field Goals Attempted', 'Field Goals Made',\n",
    "        'Longest Field Goal Made', '% of Field Goals Made', 'Extra Points Attempted', 'Extra Points Made',\n",
    "        'Extra Point Percentage', 'Kickoffs', 'Kickoff Yards', 'Kickoff Touchbacks', \n",
    "        '% Kickoff was a Touchback', 'Kickoff Average Yardage'\n",
    "        \n",
    "\n",
    "    ]\n",
    "    \n",
    "    #Punting\n",
    "    table_df_li[7].columns = [\n",
    "        'No.', 'Player', 'Age', 'Pos', 'Games Played', 'Games Started', 'Times Puned',\n",
    "        'Total Punt Yardage', 'Yards per Punt', 'Punt Return Yardage by Opposition', \n",
    "        'Punt Net yards', 'Punt Net Yards per Punt', 'Longest Punt', \n",
    "        'Punts Resulting in a Touchback', '% of Punts Resulting in a Touchback', \n",
    "        'Punts Inside Opp. 20 Yard Line', '% of Punts Downed Inside Opp. 20 Yard Line',\n",
    "        'Times Punts Blocked'\n",
    "    ]\n",
    "    \n",
    "    #defense and fumbles\n",
    "    table_df_li[8].columns = [\n",
    "        'No.', 'Player', 'Age', 'Pos', 'Games Played', 'Games Started', 'Passes Intercepted on Defense',\n",
    "        'Yards Interceptions were Returned', 'Interceptions Returned for Touchdowns', \n",
    "        'Longest Interception Return', 'Passes Defended by Defensive Player', '# Forced Fumble by Opp.', \n",
    "        '# Fumbled both Lost and Recovered by Own Team', 'Fumbles Recovered by Original Fumbler', \n",
    "        'Yards Recovered Fumbles were Returned', 'Fumbles Recovered for Touchdown', 'Sacks', \n",
    "        'Tackles Solo+Assisted', 'Solo Tackles', 'Assisted Tackles', 'Tackles for Loss', \n",
    "        'Quarterback Hits', 'Safeties Scored by Player/Team'\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    #Scoring Summary\n",
    "    table_df_li[9].columns = [\n",
    "         'No.', 'Player', 'Age', 'Pos', 'Games Played', 'Games Started', 'Rush TD', 'Reception TD', \n",
    "        'Punt Return TD', 'Kick Return TD', 'Fumble Return TD', 'Interception TD', 'Other TD', \n",
    "        'All Touchdown Scored', '2-Point Conversions Made', 'Two-Point Conversions Attempted', \n",
    "        'Defensive Two-Point Conversions', 'Extra Points Made', 'Extra Points Allowed', 'Field Goals Made',\n",
    "        'Field Goals Attempted', 'Safeties Scored by Player/Team', 'Total Points Scored by all Means',\n",
    "        'Poins per Game'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        #touchdown log\n",
    "        table_df_li[10].drop(columns=['n/a'], inplace=True)\n",
    "    \n",
    "        #opponenet touchdown log\n",
    "        table_df_li[11].drop(columns=['n/a'], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #touchdown log\n",
    "    table_df_li[10].columns = [\n",
    "        'Rank', 'Date', 'Opponent', 'Results', 'Quarter', 'Distance', 'Type', 'Detail'\n",
    "    ]\n",
    "    \n",
    "        #opponent touchdown log\n",
    "    table_df_li[11].columns = [\n",
    "        'Rank', 'Date', 'Opponent', 'Results', 'Quarter', 'Distance', 'Type', 'Detail'\n",
    "    ]\n",
    "    \n",
    "    for i in range(0, len(table_df_li)):\n",
    "        \n",
    "        num_rows = len(table_df_li[i].values)\n",
    "\n",
    "        \n",
    "        table_df_li[i].insert(1, 'Team', np.repeat(team, num_rows))\n",
    "    \n",
    "    return table_df_li\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb4aa0",
   "metadata": {},
   "source": [
    "# DF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54245c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(index=index, data=row_data, columns=columns)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ba8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_tables(tables:str, table_num:int):\n",
    "    \n",
    "    table = tables[table_num]\n",
    "\n",
    "    str_table = str(table)\n",
    "\n",
    "    start_num_str_comment_tag = str_table.find('<!--')+4\n",
    "\n",
    "    table_html = bs(str_table[start_num_str_comment_tag:], 'html.parser')\n",
    "\n",
    "    rows_tbody = table_html.find_all('tbody')[0]\n",
    "    \n",
    "    \n",
    "    #columns\n",
    "    #find thead tag to isolate col names\n",
    "    table_html = table_html.find_all('thead')[0]\n",
    "\n",
    "    # find class_ = 'poptip' to isolate col names\n",
    "    col_th_tag = table_html.find_all(class_='poptip')\n",
    "\n",
    "    # get how many column names there are\n",
    "    num_col_passing = len(col_th_tag)\n",
    "\n",
    "    # list of column names\n",
    "    columns = []\n",
    "\n",
    "    for i in range(0, num_col_passing):\n",
    "        try:\n",
    "            data = col_th_tag[i].contents[0]\n",
    "            columns.append(data)\n",
    "        except:\n",
    "            columns.append('n/a') \n",
    "    \n",
    "    \n",
    "    ##rows\n",
    "    \n",
    "    rows_tr = rows_tbody.find_all('tr')\n",
    "    \n",
    "    num_index = len(rows_tbody.find_all('th'))\n",
    "    num_rows = len(rows_tr[0].find_all('td'))\n",
    "    \n",
    "    \n",
    "    row_data = []\n",
    "\n",
    "    for i in range(0, num_index):\n",
    "        row_td = rows_tr[i].find_all('td')\n",
    "    \n",
    "        data = []\n",
    "\n",
    "        for c in range(0, num_rows):\n",
    "            \n",
    "            try:\n",
    "                if len(row_td[c].find_all('a')) > 0:\n",
    "            \n",
    "                    d = row_td[c].find_all('a')[0].contents[0]\n",
    "                    data.append(d)\n",
    "                \n",
    "                else:\n",
    "                    d = row_td[c].contents[0]\n",
    "                    data.append(d)\n",
    "            \n",
    "            except:\n",
    "                data.append('n/a')\n",
    "        \n",
    "\n",
    "        row_data.append(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    index = []\n",
    "    for i in range(0, num_index):\n",
    "    \n",
    "        try:\n",
    "            data = rows_tbody.find_all('th')[i].contents[0]\n",
    "            index.append(data)\n",
    "        except:\n",
    "            index.append('n/a')\n",
    "        \n",
    "        \n",
    "    #insert index to each row to be equal to all columns\n",
    "    for i in range(0, len(index)):\n",
    "        row_data[i].insert(0, index[i])\n",
    "    \n",
    "    df = pd.DataFrame(index=index, data=row_data, columns=columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89440040",
   "metadata": {},
   "source": [
    "# Final Save CSV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a9e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_create_dataframes_save_csv(team: str, year: int):    \n",
    "    \n",
    "    team_to_url_df = pd.DataFrame(\n",
    "        data=[\n",
    "            [\n",
    "                'crd', #Cardinals\n",
    "                'atl', #Falcons\n",
    "                'rav', #Ravens\n",
    "                'buf', #Buffalos\n",
    "                'car', #Panthers\n",
    "                'chi', #Bears\n",
    "                'cin', #Bengals\n",
    "                'cle', #Browns\n",
    "                'dal', #Cowboys\n",
    "                'den', #Broncos\n",
    "                'det', #Lions\n",
    "                'gnb', #Packers\n",
    "                'htx', #Texans\n",
    "                'clt', # Colts\n",
    "                'jax', #Jaguars\n",
    "                'kan', #Chiefs\n",
    "                'rai', #Raiders\n",
    "                'sdg', #Chargers\n",
    "                'ram', #Rams\n",
    "                'mia', #Dolphins\n",
    "                'min', #Vikings\n",
    "                'nwe', #Patriots\n",
    "                'nor', #Saints\n",
    "                'nyg', #Giants\n",
    "                'nyj', #Jets\n",
    "                'phi', #Eagles\n",
    "                'pit', #Steelers\n",
    "                'sfo', #49ers\n",
    "                'sea', #Seahawks\n",
    "                'tam', #Buccaneers\n",
    "                'oti', #Titans\n",
    "                'was' #Commanders\n",
    "            ]\n",
    "        ], \n",
    "        columns=[\n",
    "            'Cardinals',\n",
    "            'Falcons',\n",
    "            'Ravens',\n",
    "            'Buffalos',\n",
    "            'Panthers',\n",
    "            'Bears',\n",
    "            'Bengals',\n",
    "            'Browns',\n",
    "            'Cowboys',\n",
    "            'Broncos',\n",
    "            'Lions',\n",
    "            'Packers',\n",
    "            'Texans',\n",
    "            'Colts',\n",
    "            'Jaguars',\n",
    "            'Chiefs',\n",
    "            'Raiders',\n",
    "            'Chargers',\n",
    "            'Rams',\n",
    "            'Dolphins',\n",
    "            'Vikings',\n",
    "            'Patriots',\n",
    "            'Saints',\n",
    "            'Giants',\n",
    "            'Jets',\n",
    "            'Eagles',\n",
    "            'Steelers',\n",
    "            '49ers',\n",
    "            'Seahawks',\n",
    "            'Buccaneers',\n",
    "            'Titans',\n",
    "            'Commanders'\n",
    "        ])\n",
    "    \n",
    "    # string url\n",
    "    str_url = 'https://www.pro-football-reference.com/teams/{}/{}.htm'\n",
    "\n",
    "    #get team url ID\n",
    "    team_url_str = team_to_url_df[team].values[0]\n",
    "    \n",
    "    # URL\n",
    "    url = str_url.format(team_url_str, year)\n",
    "    \n",
    "    # request html text\n",
    "    tables_html_request = tables_html(url=url)\n",
    "    \n",
    "    # delay execute so not to trigger ip address block\n",
    "    time.sleep(random.randrange(7,9))\n",
    "    \n",
    "    # webscrape tables/ create dataframes\n",
    "    \n",
    "    # table name list with team and year to format\n",
    "    table_name_li = [\n",
    "        'team_stats_and_ranking_{}_{}',\n",
    "        'schedule_and_game_results_{}_{}',\n",
    "        'team_conversions_{}_{}',\n",
    "        'passing_{}_{}',\n",
    "        'rushing_and_receiving_{}_{}',\n",
    "        'kick_and_punt_returns_{}_{}',\n",
    "        'kicking_{}_{}',\n",
    "        'punting_{}_{}',\n",
    "        'defense_and_fumbles_{}_{}',\n",
    "        'scoring_summary_{}_{}',\n",
    "        'touchdown_log_{}_{}',\n",
    "        'opponent_touchdown_log_{}_{}'\n",
    "    ]\n",
    "    \n",
    "    #file location\n",
    "    file_loc = 'NFL_Data_{}/{}/'.format(year, team)\n",
    "    \n",
    "    table_num = 12\n",
    "    \n",
    "    table_df_li = [webscrape_tables(tables=tables_html_request, table_num=i) for i in range(0,table_num)]\n",
    "\n",
    "    table_df_li = fix_col_labels(table_df_li=table_df_li, team=team)\n",
    "    \n",
    "    for t in range(0, table_num):\n",
    "        \n",
    "        table_df_li[t].to_csv(file_loc+table_name_li[t].format(team, year))\n",
    "        \n",
    "    return  table_df_li\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf287ad",
   "metadata": {},
   "source": [
    "# Download CSV Files from all teams 2010-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d54cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names=[\n",
    "    'Cardinals',\n",
    "    'Falcons',\n",
    "    'Ravens',\n",
    "    'Buffalos',\n",
    "    'Panthers',\n",
    "    'Bears',\n",
    "    'Bengals',\n",
    "    'Browns',\n",
    "    'Cowboys',\n",
    "    'Broncos',\n",
    "    'Lions',\n",
    "    'Packers',\n",
    "    'Texans',\n",
    "    'Colts',\n",
    "    'Jaguars',\n",
    "    'Chiefs',\n",
    "    'Raiders',\n",
    "    'Chargers',\n",
    "    'Rams',\n",
    "    'Dolphins',\n",
    "    'Vikings',\n",
    "    'Patriots',\n",
    "    'Saints',\n",
    "    'Giants',\n",
    "    'Jets',\n",
    "    'Eagles',\n",
    "    'Steelers',\n",
    "    '49ers',\n",
    "    'Seahawks',\n",
    "    'Buccaneers',\n",
    "    'Titans',\n",
    "    'Commanders'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12cf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2010,2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0414967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this will webscrape all the teams tables from 2010-2022\n",
    "#do not run \n",
    "###                         45-60 min run\n",
    "#for team in team_names:\n",
    "#    for year in years:\n",
    "#        webscrape_create_dataframes_save_csv(team=team, year=year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328241e",
   "metadata": {},
   "source": [
    "# 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a4b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2023]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [2023]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed744abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscrape_create_dataframes_save_csv_2023(team: str, year: int):    \n",
    "    \n",
    "    team_to_url_df = pd.DataFrame(\n",
    "        data=[\n",
    "            [\n",
    "                'crd', #Cardinals\n",
    "                'atl', #Falcons\n",
    "                'rav', #Ravens\n",
    "                'buf', #Buffalos\n",
    "                'car', #Panthers\n",
    "                'chi', #Bears\n",
    "                'cin', #Bengals\n",
    "                'cle', #Browns\n",
    "                'dal', #Cowboys\n",
    "                'den', #Broncos\n",
    "                'det', #Lions\n",
    "                'gnb', #Packers\n",
    "                'htx', #Texans\n",
    "                'clt', # Colts\n",
    "                'jax', #Jaguars\n",
    "                'kan', #Chiefs\n",
    "                'rai', #Raiders\n",
    "                'sdg', #Chargers\n",
    "                'ram', #Rams\n",
    "                'mia', #Dolphins\n",
    "                'min', #Vikings\n",
    "                'nwe', #Patriots\n",
    "                'nor', #Saints\n",
    "                'nyg', #Giants\n",
    "                'nyj', #Jets\n",
    "                'phi', #Eagles\n",
    "                'pit', #Steelers\n",
    "                'sfo', #49ers\n",
    "                'sea', #Seahawks\n",
    "                'tam', #Buccaneers\n",
    "                'oti', #Titans\n",
    "                'was' #Commanders\n",
    "            ]\n",
    "        ], \n",
    "        columns=[\n",
    "            'Cardinals',\n",
    "            'Falcons',\n",
    "            'Ravens',\n",
    "            'Buffalos',\n",
    "            'Panthers',\n",
    "            'Bears',\n",
    "            'Bengals',\n",
    "            'Browns',\n",
    "            'Cowboys',\n",
    "            'Broncos',\n",
    "            'Lions',\n",
    "            'Packers',\n",
    "            'Texans',\n",
    "            'Colts',\n",
    "            'Jaguars',\n",
    "            'Chiefs',\n",
    "            'Raiders',\n",
    "            'Chargers',\n",
    "            'Rams',\n",
    "            'Dolphins',\n",
    "            'Vikings',\n",
    "            'Patriots',\n",
    "            'Saints',\n",
    "            'Giants',\n",
    "            'Jets',\n",
    "            'Eagles',\n",
    "            'Steelers',\n",
    "            '49ers',\n",
    "            'Seahawks',\n",
    "            'Buccaneers',\n",
    "            'Titans',\n",
    "            'Commanders'\n",
    "        ])\n",
    "    \n",
    "    # string url\n",
    "    str_url = 'https://www.pro-football-reference.com/teams/{}/{}.htm'\n",
    "\n",
    "    #get team url ID\n",
    "    team_url_str = team_to_url_df[team].values[0]\n",
    "    \n",
    "    # URL\n",
    "    url = str_url.format(team_url_str, year)\n",
    "    \n",
    "    # request html text\n",
    "    tables_html_request = tables_html(url=url)\n",
    "    \n",
    "    # delay execute so not to trigger ip address block\n",
    "    time.sleep(random.randrange(7,9))\n",
    "    \n",
    "    # webscrape tables/ create dataframes\n",
    "    \n",
    "    # table name list with team and year to format\n",
    "    table_name_li = [\n",
    "        'team_stats_and_ranking_{}_{}',\n",
    "        'schedule_and_game_results_{}_{}',\n",
    "        'team_conversions_{}_{}',\n",
    "        'passing_{}_{}',\n",
    "        'rushing_and_receiving_{}_{}',\n",
    "        'kick_and_punt_returns_{}_{}',\n",
    "        'kicking_{}_{}',\n",
    "        'punting_{}_{}',\n",
    "        'defense_and_fumbles_{}_{}',\n",
    "        'scoring_summary_{}_{}',\n",
    "        'touchdown_log_{}_{}',\n",
    "        'opponent_touchdown_log_{}_{}'\n",
    "    ]\n",
    "    \n",
    "    #file location\n",
    "    file_loc = 'NFL_Data_{}/{}/'.format(year, team)\n",
    "    \n",
    "    table_num = 12\n",
    "    \n",
    "    table_df_li = [webscrape_tables(tables=tables_html_request[1:], table_num=i) for i in range(0,table_num)]\n",
    "\n",
    "    table_df_li = fix_col_labels(table_df_li=table_df_li, team=team)\n",
    "    \n",
    "    for t in range(0, table_num):\n",
    "        \n",
    "        table_df_li[t].to_csv(file_loc+table_name_li[t].format(team, year))\n",
    "        \n",
    "    return  table_df_li\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c4b236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for team in team_names:\n",
    "    for year in years:\n",
    "        webscrape_create_dataframes_save_csv_2023(team=team, year=year) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbbf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920dfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort teams alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c68eb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "        data=[\n",
    "            [\n",
    "                'crd', #Cardinals\n",
    "                'atl', #Falcons\n",
    "                'rav', #Ravens\n",
    "                'buf', #Buffalos\n",
    "                'car', #Panthers\n",
    "                'chi', #Bears\n",
    "                'cin', #Bengals\n",
    "                'cle', #Browns\n",
    "                'dal', #Cowboys\n",
    "                'den', #Broncos\n",
    "                'det', #Lions\n",
    "                'gnb', #Packers\n",
    "                'htx', #Texans\n",
    "                'clt', #Colts\n",
    "                'jax', #Jaguars\n",
    "                'kan', #Chiefs\n",
    "                'rai', #Raiders\n",
    "                'sdg', #Chargers\n",
    "                'ram', #Rams\n",
    "                'mia', #Dolphins\n",
    "                'min', #Vikings\n",
    "                'nwe', #Patriots\n",
    "                'nor', #Saints\n",
    "                'nyg', #Giants\n",
    "                'nyj', #Jets\n",
    "                'phi', #Eagles\n",
    "                'pit', #Steelers\n",
    "                'sfo', #49ers\n",
    "                'sea', #Seahawks\n",
    "                'tam', #Buccaneers\n",
    "                'oti', #Titans\n",
    "                'was' #Commanders\n",
    "            ]\n",
    "        ], \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "411879af",
   "metadata": {},
   "outputs": [],
   "source": [
    "        columns=[\n",
    "            'Cardinals',\n",
    "            'Falcons',\n",
    "            'Ravens',\n",
    "            'Buffalos',\n",
    "            'Panthers',\n",
    "            'Bears',\n",
    "            'Bengals',\n",
    "            'Browns',\n",
    "            'Cowboys',\n",
    "            'Broncos',\n",
    "            'Lions',\n",
    "            'Packers',\n",
    "            'Texans',\n",
    "            'Colts',\n",
    "            'Jaguars',\n",
    "            'Chiefs',\n",
    "            'Raiders',\n",
    "            'Chargers',\n",
    "            'Rams',\n",
    "            'Dolphins',\n",
    "            'Vikings',\n",
    "            'Patriots',\n",
    "            'Saints',\n",
    "            'Giants',\n",
    "            'Jets',\n",
    "            'Eagles',\n",
    "            'Steelers',\n",
    "            '49ers',\n",
    "            'Seahawks',\n",
    "            'Buccaneers',\n",
    "            'Titans',\n",
    "            'Commanders'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b62ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72f0077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
